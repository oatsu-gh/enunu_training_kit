###########################################################
#               GENERAL SETTINGS                          #
###########################################################
etk_version: "2.0.0-dev" # NOTE: DO NOT CHANGE

## The name of singer
spk: "Kodoku"

## exp tag(for managing experiments)
tag: "ETK_test_0826"

# Pretrained model dir (leave empty to disable)
pretrained_expdir:

## Directory of Unzipped singing voice database
# PLEASE CHANGE THE PATH BASED ON YOUR ENVIRONMENT
db_root: "DB"

## Output directory
# All the generated labels, intermediate files, and segmented wav files
# will be saved in the following directory
out_dir: "data"

# # Audio sampling rate
# # CAUTION: Changing sample_rate may affect the dimension number of acoustic features.
# # DO NOT CHANGE this unless you know the relationship between the dim of bap and sample_rate.
sample_rate: 48000

## Songs to be excluded from training.
exclude_songs: []

## dev / train_no_dev / eval split rule
list_by: segment # default: segment ("segment" or "song")

### Utaupy related settings.
## Utaupy table path
# This singing voice database contains the unvoiced vowels "I" and "U".
# To enable the unvoiced vowels, modified version of sinsy dictionary files
# are needed.
utaupy_table_path: "dic/kana2phonemes_etk_001.table"

## HTS-style question used for extracting musical/linguistic context from musicxml files
question_path: "hed/jp_etk_002.hed"

###########################################################
#                DATA PREPROCESS SETTINGS                 #
###########################################################
## How to segment LAB and WAV before training on stage-0
## Long pauses over `max_pause_duration` will be removed.
## Each segment length will be shorter than `max_segment_length`.
max_pause_duration: 4 # default: 4 [s] これより長い休符を除去して学習します。
max_segment_length: 30 # default: 30 [s] この長さよりなるべく短くなるように分割して学習します。
## Choices are [strict, middle, lenient]
vowel_duration_check: middle

###########################################################
#                FEATURE EXTRACTION SETTING               #
###########################################################

timelag_features: defaults
duration_features: defaults
acoustic_features: nnsvs_contrib_static_only

# Parameter trajectory smoothing
# Ref: The NAIST Text-to-Speech System for the Blizzard Challenge 2015
trajectory_smoothing: false
trajectory_smoothing_cutoff: 50

###########################################################
#                TRAINING SETTING                         #
###########################################################

# Models
# To customize, put your config or change ones in
# conf/train/{timelag,duration,acoustic}/ and
# specify the config name below
# NOTE: *_model: model definition, *_train: general train configs,
# *_data: data configs (e.g., batch size)

timelag_model: etk_timelag_vp_mdn
timelag_train: etk_timelag_schedulefree
timelag_data: etk_timelag

duration_model: etk_duration_vp_mdn
duration_train: etk_duration_schedulefree
duration_data: etk_duration

acoustic_model: etk_acoustic_nnsvs_world_multi_ar_f0_diff_mgcbap
acoustic_train: etk_acoustic_diffusion_schedulefree
acoustic_data: etk_acoustic_world_diffusion

postfilter_model: postfilter_bap
postfilter_train: bap
postfilter_data: myconfig

# Advanced settings for hyperparameter search with Hydra and Optuna.
# https://hydra.cc/docs/plugins/optuna_sweeper/
# NOTE: Don't use spaces for each search space configuration.
# OK: data.batch_size=range(1,16)
# NG: data.batch_size=range(1, 16)
# Example 1: data.batch_size=range(1,16) model.netG.hidden_dim=choice(32,64,128)
# Example 2: train.optim.optimizer.params.lr=interval(0.0001,0.01)
timelag_hydra_optuna_sweeper_args:
timelag_hydra_optuna_sweeper_n_trials: 100
duration_hydra_optuna_sweeper_args:
duration_hydra_optuna_sweeper_n_trials: 100
acoustic_hydra_optuna_sweeper_args:
acoustic_hydra_optuna_sweeper_n_trials: 100

###########################################################
#                SYNTHESIS SETTING                        #
###########################################################
# conf/synthesis/synthesis/${synthesis}
# If you use uSFGAN or SiFi-GAN, please set `world_gv_usfgan` or `melf0_gv_usfgan`
synthesis: world_gv_usfgan

# latest.pth or best_loss.pth
timelag_eval_checkpoint: best_loss.pth
duration_eval_checkpoint: best_loss.pth
acoustic_eval_checkpoint: latest.pth
postfilter_eval_checkpoint: latest.pth

# wav dtype
dtype: float32

###########################################################
#                VOCODER SETTING                          #
###########################################################

# NOTE: conf/usfgan/${vocoder_model}.yaml must exist.
# NOTE: vocoder_model is equal to vocoder_generator
vocoder_model: etk_world_parallel_hn_usfgan_sr48k
vocoder_data: etk_world_sr48k
vocoder_discriminator: etk_univnet
vocoder_train: etk_hn_usfgan_sr48k

# Pretrained checkpoint path for the vocoder model
# NOTE: if you want to try fine-tuning, please specify the path here
# absolute/relative path to the checkpoint
pretrained_vocoder_checkpoint:

# NOTE: the checkpoint is used for synthesis and packing
# This doesn't have any effect on training
vocoder_eval_checkpoint:
